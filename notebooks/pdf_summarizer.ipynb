{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader, PyPDFLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(file_path=\"./data/harrypotter1_short.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document(s) in your data\n",
      "There are 66762 characters in your sample document\n",
      "Here is a sample: Harry Potter and the Sorcerer's Stone\n",
      "\n",
      "\n",
      "CHAPTER ONE\n",
      "\n",
      "THE BOY WHO LIVED\n",
      "\n",
      "Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say\n",
      "that they were perfectly normal, thank you very much. They\n"
     ]
    }
   ],
   "source": [
    "print (f'You have {len(data)} document(s) in your data')\n",
    "print (f'There are {len(data[0].page_content)} characters in your sample document')\n",
    "print (f'Here is a sample: {data[0].page_content[:200]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create chunks from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=150)\n",
    "texts = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 198 documents\n"
     ]
    }
   ],
   "source": [
    "print (f'Now you have {len(texts)} documents')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate summaries using custom T5 based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'jruranski/flan-t5-small-samsum'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline, AutoModelForCausalLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('gpu' if torch.cuda.is_available() else 'cpu')\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(model_id, load_in_8bit=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    max_length=700\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter and the Sorcerer's Stone were proud to say that they were perfectly normal.\n"
     ]
    }
   ],
   "source": [
    "print(local_llm('summarize: ' + data[0].page_content[:400] + '...'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_texts = texts[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = [local_llm(\"summarize: \" + chunk.page_content) for chunk in sum_texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='When Mr. and Mrs. Dursley woke up on the dull, gray Tuesday our story\\nstarts, there was nothing about the cloudy sky outside to suggest that\\nstrange and mysterious things would soon be happening all over the\\ncountry. Mr. Dursley hummed as he picked out his most boring tie for\\nwork, and Mrs. Dursley gossiped away happily as she wrestled a screaming\\nDudley into his high chair.\\n\\nNone of them noticed a large, tawny owl flutter past the window.' metadata={'source': './data/harrypotter1_short.txt'}\n",
      "==================\n",
      "Summary generated: \n",
      "Mr. and Mrs. Dursley woke up on the dull, gray Tuesday.\n"
     ]
    }
   ],
   "source": [
    "print(texts[4])\n",
    "print(\"==================\\nSummary generated: \")\n",
    "print(summaries[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create embeddings in vector store (Chroma) from chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (0.0.340)\n",
      "Requirement already satisfied: sentence_transformers in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from langchain) (2.0.23)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from langchain) (3.9.1)\n",
      "Requirement already satisfied: anyio<4.0 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from langchain) (3.7.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from langchain) (0.6.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from langchain) (0.0.69)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from langchain) (1.26.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from langchain) (2.5.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from sentence_transformers) (4.36.0)\n",
      "Requirement already satisfied: tqdm in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from sentence_transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from sentence_transformers) (2.1.1)\n",
      "Requirement already satisfied: torchvision in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from sentence_transformers) (0.16.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from sentence_transformers) (1.3.2)\n",
      "Requirement already satisfied: scipy in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from sentence_transformers) (1.11.4)\n",
      "Requirement already satisfied: nltk in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from sentence_transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from sentence_transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from sentence_transformers) (0.19.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from anyio<4.0->langchain) (3.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from anyio<4.0->langchain) (1.3.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: filelock in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.14.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from requests<3,>=2->langchain) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
      "Requirement already satisfied: sympy in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.4.1)\n",
      "Requirement already satisfied: click in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from nltk->sentence_transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from nltk->sentence_transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from torchvision->sentence_transformers) (10.1.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/jruranski/miniforge3/envs/colab/lib/python3.11/site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.03844855725765228, -0.055053550750017166, -0.015172900632023811]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'This is a test document'\n",
    "query_result = embeddings.embed_query(text)\n",
    "query_result[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create documents from the summaries\n",
    "\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Save the combinded summaries to a file\n",
    "with open('./data/summaries.txt', 'w') as f:\n",
    "    for summary in summaries:\n",
    "        f.write(summary + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(file_path=\"./data/summaries.txt\")\n",
    "summary_data = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=150)\n",
    "texts = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorstore = Chroma.from_documents(texts, embeddings)\n",
    "vectorstore = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Who is Dudley?'\n",
    "docs = vectorstore.similarity_search(query, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gordon were all big and stupid, but as Dudley was the biggest and\n",
      "stupidest of the lot, he was the leader. The rest of them were all quite\n",
      "happy to join in Dudley's favorite sport: Harry Hunting.\n",
      "Harry was frying eggs by the time Dudley arrived in the kitchen with his\n",
      "mother. Dudley looked a lot like Uncle Vernon. He had a large pink face,\n",
      "not much neck, small, watery blue eyes, and thick blond hair that lay\n",
      "was almost hidden beneath all Dudley's birthday presents. It looked as\n",
      "though Dudley had gotten the new computer he wanted, not to mention the\n",
      "second television and the racing bike. Exactly why Dudley wanted a\n",
      "of Dudley's, and Dudley was about four times bigger than he was. Harry\n",
      "had a thin face, knobbly knees, black hair, and bright green eyes. He\n",
      "wore round glasses held together with a lot of Scotch tape because of\n",
      "not much neck, small, watery blue eyes, and thick blond hair that lay\n",
      "smoothly on his thick, fat head. Aunt Petunia often said that Dudley\n",
      "looked like a baby angel -- Harry often said that Dudley looked like a\n",
      "pig in a wig.\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print ( doc.page_content[:400])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a chat interface with OpenAI GPT-3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY', 'YourAPIKeyIfNotSet')\n",
    "print(OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OpenAI' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/jruranski/Developer/Langchain/pdf_summarizer.ipynb Cell 33\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jruranski/Developer/Langchain/pdf_summarizer.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m llm \u001b[39m=\u001b[39m OpenAI(temperature\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, openai_api_key\u001b[39m=\u001b[39mOPENAI_API_KEY)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'OpenAI' is not defined"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0.2, openai_api_key=OPENAI_API_KEY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
