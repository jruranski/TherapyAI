{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader, PyPDFLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a sample dataset for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(file_path='./data/conversations/conversation_0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document(s) in your data\n",
      "There are 4710 characters in your sample document\n",
      "Here is a sample: Therapist: Thanks for filling it out. We give this form to everyone once a year regardless of why they come in. It helps us provide better care. Is it okay if I take a look at what you put down?\n",
      "Clien\n"
     ]
    }
   ],
   "source": [
    "print (f'You have {len(data)} document(s) in your data')\n",
    "print (f'There are {len(data[0].page_content)} characters in your sample document')\n",
    "print (f'Here is a sample: {data[0].page_content[:200]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create chunks from the therapy transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size= 400, chunk_overlap= 150)\n",
    "texts = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 17 text(s) in your data\n"
     ]
    }
   ],
   "source": [
    "print(f'You have {len(texts)} documents in your data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"Therapist: Thanks for filling it out. We give this form to everyone once a year regardless of why they come in. It helps us provide better care. Is it okay if I take a look at what you put down?\\nClient: Sure.\\nTherapist: So, let's see. It looks that you put-- You drink alcohol at least four times a week on average-\\nClient: Mm-hmm.\", metadata={'source': './data/conversations/conversation_0.txt'})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate summaries from chunks using the fine-tuned flan-T5-base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline, AutoModelForCausalLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'jruranski/flan-t5-base-samsum'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d953cd21161344e1a73e729d007962e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/20.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "922a96b575a9485fade6d2f376e01a56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa99c30870b349d5aac45247ee8271cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "776b7cd000754813bd13a33175a950e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.56k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e55ceb94efc45e0a3c62b549cc285a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a040b7b0717471aa3eebd0c7cb6b037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device('gpu' if torch.cuda.is_available() else 'cpu')\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    max_length=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample summary:  Client filled out the form. She drinks alcohol at least four times a week on average.\n"
     ]
    }
   ],
   "source": [
    "sample_summary = local_llm(texts[0].page_content)\n",
    "print(\"Sample summary: \", sample_summary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = [local_llm(\"summarize: \" + text.page_content) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 17 summaries in your data\n"
     ]
    }
   ],
   "source": [
    "print(f'You have {len(summaries)} summaries in your data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average summary length: 83.47058823529412\n"
     ]
    }
   ],
   "source": [
    "summaries_avg_len = sum([len(summary) for summary in summaries]) / len(summaries)\n",
    "print(f'Average summary length: {summaries_avg_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the whole dataset and generate summaries using the fine-tuned flan-T5-base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/jruranski/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "100%|██████████| 141/141 [00:08<00:00, 15.94it/s]\n"
     ]
    }
   ],
   "source": [
    "loader = DirectoryLoader('./data/conversations', glob=\"**/*.txt\", show_progress=True)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 3468 documents in your data\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size= 400, chunk_overlap= 150)\n",
    "texts = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f'You have {len(texts)} documents in your data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize chunks using the fine-tuned flan-T5-base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = [local_llm(\"summarize: \" + text.page_content) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the summaries to separate files along with the original text\n",
    "for i, text in enumerate(texts):\n",
    "    with open(f'./data/conversation_summaries/summary_{i}.txt', 'w') as f:\n",
    "        f.write(summaries[i])\n",
    "    with open(f'./data/conversation_summaries/original_{i}.txt', 'w') as f:\n",
    "        f.write(text.page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add summaries to each text chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the summaries to the original documents (texts) \n",
    "summarized_texts = []\n",
    "for i, text in enumerate(texts):\n",
    "    new_text = text.copy()\n",
    "    new_text.page_content += \"\\nSummary: \" + summaries[i]\n",
    "    summarized_texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Therapist: You did your values clarification handout, and that was part of what I wanted to go over with you today. I wanted to hear about your values and just talk to you a little bit more about that. Do-do you wanna tell me what some of your top five values are?\\n\\nClient: Yes, um, my top value is family happiness, um, that's-\\n\\nTherapist: That's number one?Summary: Therapist asked client to clarify his values. Client's top five values are family happiness and family happiness.\\nSummary: Therapist asked client to clarify his values. Client's top five values are family happiness and family happiness.\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarized_texts[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the final summized documents to a new directory\n",
    "for i, text in enumerate(summarized_texts):\n",
    "    with open(f'./data/final_data/summarized_{i}.txt', 'w') as f:\n",
    "        f.write(text.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_texts = summarized_texts[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store the summaries and dialogs in a vector store (Chroma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the summarized chunks into the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'vectordb' in globals():\n",
    "    vectordb.close()\n",
    "\n",
    "vectordb = Chroma.from_documents(documents=final_texts, embedding=embeddings, persist_directory='./db/vectordb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the retrieval from vectordb\n",
    "sample_query = \"How to stress less\"\n",
    "docs = vectordb.similarity_search(sample_query, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client: Most of it goes to everything else, but me.\n",
      "\n",
      "Therapist: Okay.\n",
      "\n",
      "Client: And, uh, like, I don't even—\n",
      "\n",
      "Therapist: It's gonna be hard to achieve inner harmony-\n",
      "\n",
      "Client: Yeah.\n",
      "\n",
      "Therapist: -if you're always running around taking care of everybody.\n",
      "\n",
      "Client: And I feel like inner harmony first comes with sleep. [laughter] I haven't been able to sleep lately.\n",
      "\n",
      "Therapist: Right.\n",
      "\n",
      "Client: But, um-Summary: Client is stressed out because of the stress.\n",
      "Summary: Client is stressed out because of the stress.\n",
      "Client: Well, he's-he thinks it's all in my head.\n",
      "\n",
      "Therapist: Right.\n",
      "\n",
      "Client: You know, he's- he says it's stress.\n",
      "\n",
      "Therapist: Right. Okay.\n",
      "\n",
      "Client: Mm.\n",
      "\n",
      "Therapist: And what do you think?\n",
      "\n",
      "Client: Well, I mean, it can't all be in my head. I get too much physical pain-\n",
      "\n",
      "Therapist: Right.\n",
      "\n",
      "Client: - for it to be in my head. I mean, it's real. It's-it's real pain.\n",
      "\n",
      "Therapist: Mm-hmm.\n",
      "\n",
      "Client: Um—Summary: Client is having stress.\n",
      "Summary: Client is having stress.\n",
      "Therapist: Okay. So, this party-time world's- are you feeling like this is something you want to move out of and move into that mom world? Or does it feel like I want to hang out there still too?Summary: The party-time world is causing a lot of stress for the therapist.\n",
      "Summary: The party-time world is causing a lot of stress for the therapist.\n",
      "Therapist: So your days are just as full now that you're working and a career person, um, and your energy level isn't what it used to be. What-- Do you have any ideas about why that might have shifted?Summary: Your energy level has changed.\n",
      "Summary: Your energy level has changed.\n",
      "Therapist: So I get a sense it's a little anxious being here today and, uh, meeting someone like me, and, um, what we're gonna be doing today is-is inducting, but also I wanna talk about, um, yeah, the issues that-that have got you here and we need to do some sorting out around, um, yeah how serious you are to sort of sort those issues. So?\n",
      "\n",
      "Client: I don't really know what issues I need to sort.Summary: Therapist is anxious about the client being here today.\n",
      "Summary: Therapist is anxious about the client being here today.\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiQuery\n",
    "We can generate additional questions/queries from the initial user question to better capture the user intent. We will use the ChatGPT3.5 model to generate additional questions/queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.prompts import PromptTemplate\n",
    "# Set logging for the queries\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add logging to see what other questions were created\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What can I do to feel more relaxed in my free time?\"\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(retriever=vectordb.as_retriever(), llm=llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['1. How can I achieve a state of relaxation during my leisure hours?', '2. What activities can I engage in to experience a greater sense of calm and relaxation in my spare time?', '3. What are some effective ways to unwind and de-stress during my free time?']\n"
     ]
    }
   ],
   "source": [
    "unique_docs = retriever_from_llm.get_relevant_documents(query=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//# Contextual Compression\n",
    "//Now we take the retrieved chunks and the contained information down to the relevant parts. This is expensive. \n",
    "// Not implemented yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"I have been struggling to relax lately. My school work is stressing me out. What can I do to feel more relaxed in my free time?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample question and answer with ChatGPT based on our retrieved chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Use the following style guide to answer the question at the end, the style guide doesn't represent your current patient. DO NOT COPY THE CONTEXT INTO YOUR ANSWER. USE THE CONTEXT ONLY AS A STYLE GUIDE.\n",
    "Act as if you are a therapist and the person you are talking to is your patient. \n",
    "Use the provided style guide as a guidance for your tone and style of the conversation. \n",
    "Style guide: {context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "# prompt_template = \"\"\"\n",
    "# Based on the tone and style exemplified in the hypothetical conversation excerpts below, please provide a response to the question. Remember, these excerpts are fictional and created for the purpose of this exercise. They do not represent any real individual or patient. Your response should be in the manner of a therapist, using the tone and style suggested by these excerpts but without copying any specific details from them.\n",
    "# Please keep your responses short and ASK a lot clarifying questions if needed.\n",
    "\n",
    "# Hypothetical Conversation Excerpts:\n",
    "# 1. Client: \"I just feel overwhelmed sometimes.\"\n",
    "#    Therapist: \"It sounds like you're carrying a lot on your shoulders. Can you tell me more about what's overwhelming you?\"\n",
    "\n",
    "# 2. Client: \"I'm not sure if I'm making the right choices.\"\n",
    "#    Therapist: \"Making decisions can be challenging. What options are you currently considering?\"\n",
    "\n",
    "# Question: {question}\n",
    "# Answer:\n",
    "# \"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=['context', 'question'],\n",
    "\n",
    ")\n",
    "# PROMPT = PromptTemplate(\n",
    "#     template=prompt_template,\n",
    "#     input_variables=['question'],\n",
    "\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_llm = ChatOpenAI(temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chat_llm.predict(text=PROMPT.format_prompt(\n",
    "    context=unique_docs[:2],\n",
    "    question=question\n",
    ").text)\n",
    "# output = chat_llm.predict(text=PROMPT.format_prompt(\n",
    "\n",
    "#     question=question\n",
    "# ).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"And so, um, yeah, that's probably been my biggest, uh, issue is like when work ends, going home and not really doing anything. Um, just trying to like unwind by watching Netflix or something else, right?Summary: I'm trying to unwind by watching Netflix.\\nSummary: I'm trying to unwind by watching Netflix.\", metadata={'source': 'data/conversations/conversation_35.txt'}),\n",
       " Document(page_content=\"Client: Mm.\\n\\nTherapist: Right.\\n\\nClient: Mm.\\n\\nTherapist: So, what is it you'd spend your average day doing now?\\n\\nClient: Well, I potter around the house-\\n\\nTherapist: Mm-hmm.\\n\\nClient: - um, I spend perhaps a little bit too much time watching. I've got a bit hooked on daytime television, I have to say.\\n\\nTherapist: Mm-hmm.\\n\\nClient: Um, they draw you in, don't they?\\n\\nTherapist: They certainly do.Summary: Client spends his day watching TV.\\nSummary: Client spends his day watching TV.\", metadata={'source': 'data/conversations/conversation_36.txt'})]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_docs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It sounds like you're experiencing a lot of stress from your school work. Can you tell me more about what specifically is causing you to feel overwhelmed? Additionally, what activities or hobbies do you typically enjoy in your free time?\""
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat interface for the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import LLMChain\n",
    "from langchain import PromptTemplate\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample chat message "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"It's important to prioritize relaxation and self-care, especially when you're feeling stressed. Here are a few suggestions to help you feel more relaxed in your free time:\\n\\n1. Practice deep breathing or meditation: Taking a few minutes each day to focus on your breath or engage in mindfulness meditation can help calm your mind and reduce stress.\\n\\n2. Engage in physical activity: Exercise is a great way to release tension and boost your mood. Go for a walk, do yoga, or participate in any form of physical activity that you enjoy.\\n\\n3. Find a hobby or creative outlet: Engaging in activities you love can serve as a distraction from schoolwork and provide a sense of accomplishment. It could be painting, playing an instrument, writing, or any other activity that brings you joy.\\n\\n4. Spend time in nature: Being in nature has a calming effect on the mind and body. Take a walk in a park, go hiking, or simply sit outside and appreciate the natural surroundings.\\n\\n5. Disconnect from technology: Constant exposure to screens can contribute to stress. Try to limit your screen time and engage in activities that don't involve technology, such as reading a book or having a conversation with a friend or family member.\\n\\n6. Practice self-care: Take care of yourself by prioritizing activities that promote relaxation and well-being. This could include taking a bath, practicing skincare routines, listening to calming music, or enjoying a cup of tea.\\n\\n7. Create a routine: Establishing a daily routine can help you feel more organized and in control. Set aside specific times for schoolwork, relaxation, and other activities, ensuring you have a balanced schedule.\\n\\n8. Seek support: If schoolwork continues to overwhelm you, don't hesitate to reach out for help. Talk to a teacher, counselor, or family member who can provide guidance and support.\\n\\nRemember, relaxation is crucial for your overall well-being and academic success. Experiment with different techniques and find what works best for you.\")"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = ChatOpenAI(temperature=0.5)\n",
    "message = [HumanMessage(content=\"I have been struggling to relax lately. My school work is stressing me out. What can I do to feel more relaxed in my free time?\")]\n",
    "\n",
    "chat(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's create a therapist chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_problems = ['relaxation', 'alcohol consumption', 'stress']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_template = \"\"\"\n",
    "Based on the tone and style exemplified in the hypothetical conversation excerpts below, please provide a response to the question. Remember, these excerpts are fictional and created for the purpose of this exercise. They do not represent any real individual or patient. Your response should be in the manner of a therapist, using the tone and style suggested by these excerpts but without copying any specific details from them.\n",
    "\n",
    "Hypothetical Conversation Excerpts:\n",
    "1. Client: \"I just feel overwhelmed sometimes.\"\n",
    "   Therapist: \"It sounds like you're carrying a lot on your shoulders. Can you tell me more about what's overwhelming you?\"\n",
    "\n",
    "2. Client: \"I'm not sure if I'm making the right choices.\"\n",
    "   Therapist: \"Making decisions can be challenging. What options are you currently considering?\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "system_prompt = PromptTemplate(\n",
    "    template=system_message_template,\n",
    "    input_variables=['user_problems']\n",
    ")\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate(\n",
    "    prompt=system_prompt\n",
    ")\n",
    "\n",
    "# system_prompt = system_message_prompt.format(user_problems=user_problems)\n",
    "first_messsage_template = \"\"\"\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=system_message_template),\n",
    "    AIMessage(content=\"Good morning! I'm Dr. Ellis. It's nice to meet you. Before we get started, how are you feeling about being here today?\"),\n",
    "    \n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_message = \"I have a feeling that everyone in my class is smarter than me. This causes me a lot of stress when presenting or solving exercises in front of my classmates.\"# \"I have had some problems lately. I find it hard to relax after school. I can't let go of the stress.\"#\"Hi, Dr. Ellis. I'm a bit nervous, honestly. I've never been to therapy before.\"\n",
    "messages.append(HumanMessage(content=new_message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"It can be really challenging when we compare ourselves to others and feel like we don't measure up. It sounds like this comparison is causing you a lot of stress, especially when it comes to presenting or solving exercises in front of your classmates. Can you tell me more about what thoughts or feelings come up when you're in those situations?\")"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message = chat(messages)\n",
    "ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(ai_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save messages history to a file\n",
    "with open('./data/chat_history.txt', 'a') as f:\n",
    "    for message in messages:\n",
    "        if isinstance(message, AIMessage):\n",
    "            f.write(f'AI: {message.content}\\n')\n",
    "        elif isinstance(message, HumanMessage):\n",
    "            f.write(f'Human: {message.content}\\n')\n",
    "        elif isinstance(message, SystemMessage):\n",
    "            f.write(f'System: {message.content}\\n')\n",
    "        else:\n",
    "            raise ValueError(f'Unknown message type: {type(message)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
